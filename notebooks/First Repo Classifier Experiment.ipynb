{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Purpose \n",
    "\n",
    "Here we are experimenting with semi-supervised learning. We have prepared =~ 80 examples for our initial model. We will then use this model to classify more data, and then that model to classify more data, cyclically until we arrive at our goal of a good classifier.\n",
    "\n",
    "## Classifying Educational Projects\n",
    "\n",
    "The goal of this project is to classify github projects as primarily educational or not. This classification will then feed into a time series analysis of educational content on Github over time.\n",
    "\n",
    "## First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_edu': 0,\n",
       " 'readme_words': ['htf', 'hack', 'future', 'net', 'challenge'],\n",
       " 'repo': 'Djohnnie/HTF2017'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os, re\n",
    "import json, csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# =~ 80 examples done by hand... lets see if we can use semi-supervised learning to improve our training data!\n",
    "raw_training_data = []\n",
    "with open('../data/html/first_training.jsonl') as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        raw_training_data.append(record)\n",
    "raw_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nos average: 143.06976744186048, median: 77.0\n",
      "Yes average: 1003.1818181818181, median: 231.0\n",
      "README word count/education normalized cross correlation: 2.25\n"
     ]
    }
   ],
   "source": [
    "# Add the number of words, as it is a strong signal\n",
    "len_nos = [len(doc['readme_words']) for doc in raw_training_data if doc['is_edu'] == 0]\n",
    "len_yes = [len(doc['readme_words']) for doc in raw_training_data if doc['is_edu'] == 1]\n",
    "len_all = [len(doc['readme_words']) for doc in raw_training_data]\n",
    "max_all = max(len_all)\n",
    "normalized_all = [x/max_all for x in len_all]\n",
    "values = [doc['is_edu'] for doc in raw_training_data]\n",
    "\n",
    "print('Nos average: {}, median: {}'.format(np.average(len_nos), np.median(len_nos)))\n",
    "print('Yes average: {}, median: {}'.format(np.average(len_yes), np.median(len_yes)))\n",
    "\n",
    "print('README word count/education normalized cross correlation: {0:.2f}'.format(\n",
    "    np.correlate(values, normalized_all)[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'htf hack future net challenge'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_words = [' '.join(doc['readme_words']) for doc in raw_training_data]\n",
    "just_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_values = [doc['is_edu'] for doc in raw_training_data]\n",
    "just_values = np.array(just_values)\n",
    "just_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjurney/anaconda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7,437 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_WORDS=1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(just_words)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(just_words)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "\n",
    "print('Found {:,} unique tokens.'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 1000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "\n",
    "MAX_WORDS_PER_DOC=1000\n",
    "\n",
    "padded_sequences = preprocessing.sequence.pad_sequences(\n",
    "    sequences,\n",
    "    maxlen=MAX_WORDS_PER_DOC\n",
    ")\n",
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append word count feature to feature matrix\n",
    "len_all = [len(doc['readme_words']) for doc in raw_training_data]\n",
    "\n",
    "len_all = [[x] for x in len_all]\n",
    "len_all = np.array(len_all)\n",
    "sequences_and_lengths = np.append(padded_sequences, len_all, axis=1)\n",
    "assert sequences_and_lengths.shape == (76, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sort data\n",
    "indices = np.arange(sequences_and_lengths.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = padded_sequences[indices]\n",
    "labels = just_values[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, \n",
    "    labels, \n",
    "    test_size=0.2,\n",
    "    random_state=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+\n",
      "| Average  | Median   | Minimum  | Maximum  |\n",
      "+----------+----------+----------+----------+\n",
      "| 67.1875f | 68.7500f | 75.0000f | 62.5000f |\n",
      "+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Dropout, LSTM\n",
    "from table import Table\n",
    "\n",
    "TRAINING_RUNS = 12\n",
    "\n",
    "accuracies = []\n",
    "for i in range(TRAINING_RUNS):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            vocab_size, \n",
    "            64, \n",
    "            input_length=MAX_WORDS_PER_DOC\n",
    "        )\n",
    "    )\n",
    "    model.add(Flatten())\n",
    "    model.add(\n",
    "        Dense(32, activation='relu')\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(32, activation='relu')\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(1, activation='sigmoid')\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['acc', 'mse', 'mae', 'mape', 'cosine']\n",
    "    )\n",
    "    #model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "        validation_split=0.3,\n",
    "        verbose=0\n",
    "    )\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    #print(Table(model.metrics_names, [scores]))\n",
    "    \n",
    "    accuracy_pct = scores[1] * 100\n",
    "    accuracies.append(accuracy_pct)\n",
    "\n",
    "print(\n",
    "    Table(\n",
    "        ['Average','Median','Minimum','Maximum'],\n",
    "        [[np.average(accuracies), np.median(accuracies), np.max(accuracies), np.min(accuracies)]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/html/documents.jsonl') as f:\n",
    "    second_raw_training = []\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        second_raw_training.append(record)\n",
    "\n",
    "second_raw_training = random.sample(second_raw_training, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_just_words = [' '.join(doc['readme_words']) for doc in second_raw_training]\n",
    "\n",
    "second_sequences = tokenizer.texts_to_sequences(second_just_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_truncated = preprocessing.sequence.pad_sequences(\n",
    "    second_sequences,\n",
    "    maxlen=MAX_WORDS_PER_DOC\n",
    ")\n",
    "second_truncated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/garyp/sifter',\n",
       " 'https://github.com/crysisfarcry222/rapidjson',\n",
       " 'https://github.com/jonsuh/mcgriddle',\n",
       " 'https://github.com/MattNguyen/exfile-s3',\n",
       " 'https://github.com/DIKU-EDU/remarks',\n",
       " 'https://github.com/sourcegraph/syntect_server',\n",
       " 'https://github.com/sit/handson-strace',\n",
       " 'https://github.com/flidw55/nfu40341127',\n",
       " 'https://github.com/pwr/Solaar',\n",
       " 'https://github.com/UK-MAC/mega-stream',\n",
       " 'https://github.com/matthewelse/micropython',\n",
       " 'https://github.com/jeescu/react-firebase',\n",
       " 'https://github.com/Yogeshkad/gulp',\n",
       " 'https://github.com/dkruchinin/particles',\n",
       " 'https://github.com/fraserxu/react-testing-recipes',\n",
       " 'https://github.com/AzureAD/microsoft-authentication-library-for-dotnet',\n",
       " 'https://github.com/AlexarJING/awesome-love2d',\n",
       " 'https://github.com/USGS-WiM/sparrow-eastern-us-js',\n",
       " 'https://github.com/curlykale/zheng',\n",
       " 'https://github.com/shanjgit/tensorflow-generative-model-collections',\n",
       " 'https://github.com/Daniel-Santhanaraj/tripguru',\n",
       " 'https://github.com/vporta/tradier-client',\n",
       " 'https://github.com/robocoder/rips-scanner',\n",
       " 'https://github.com/gebv/gorush',\n",
       " 'https://github.com/waleedsamy/exwml',\n",
       " 'https://github.com/Erik-ly/neo4j-shell-tools',\n",
       " 'https://github.com/MilesRomney/spontaneous',\n",
       " 'https://github.com/ocelot-collab/ocelot',\n",
       " 'https://github.com/itbj/iosxrv-x64-vbox',\n",
       " 'https://github.com/pote/int',\n",
       " 'https://github.com/mratsim/Amazon-Forest-Computer-Vision',\n",
       " 'https://github.com/skybet/canvass',\n",
       " 'https://github.com/rsmeral/puck.js',\n",
       " 'https://github.com/onelogin/php-saml',\n",
       " 'https://github.com/Madrox/django-apiview',\n",
       " 'https://github.com/bluegenes/MakeMyTranscriptome',\n",
       " 'https://github.com/victorlaerte/dumbest-ipsum',\n",
       " 'https://github.com/PaoPaoRobotGroup/ygz-slam',\n",
       " 'https://github.com/learn-co-students/receiving-api-posts-web-051517',\n",
       " 'https://github.com/nii236/leeroyci',\n",
       " 'https://github.com/snehaghosh91/BigDataProject',\n",
       " 'https://github.com/enddo/Hack-Night',\n",
       " 'https://github.com/G-Bruin/laravel-socket',\n",
       " 'https://github.com/Boka44/weather',\n",
       " 'https://github.com/goldyliang/FBReader_FTS_AndroidStudio',\n",
       " 'https://github.com/OWASP/json-sanitizer',\n",
       " 'https://github.com/google/ts-style',\n",
       " 'https://github.com/GaneshAnthati/policybot',\n",
       " 'https://github.com/learn-co-students/javascript-rock-dodger-bootcamp-prep-000',\n",
       " 'https://github.com/subzerocloud/pg-amqp-bridge',\n",
       " 'https://github.com/tom-daly/sp2013-bootstrap-nav',\n",
       " 'https://github.com/atomnuker/glauss',\n",
       " 'https://github.com/delahaya/awesome-command-line-apps',\n",
       " 'https://github.com/barbar/vortigern',\n",
       " 'https://github.com/bigtruedata/wercker-step-install-node',\n",
       " 'https://github.com/ashislaha/FrameWorkCreationAndDistribution',\n",
       " 'https://github.com/anoopsarkar/cgw',\n",
       " 'https://github.com/ordnungswidrig/jugs-clojure',\n",
       " 'https://github.com/wpilibsuite/EclipsePlugins',\n",
       " 'https://github.com/JoeKarlsson/Angular-Instafeed',\n",
       " 'https://github.com/decisively/wink-bm25-text-search',\n",
       " 'https://github.com/JuliaMath/GSL.jl',\n",
       " 'https://github.com/haljin/erlesy',\n",
       " 'https://github.com/lhp7895/shadowsocksr-android-20161229',\n",
       " 'https://github.com/CSE512-14W/fp-ljorr1-jortiz16',\n",
       " 'https://github.com/themathgeek13/N-Body-Simulations-CUDA',\n",
       " 'https://github.com/laiyuandong/test',\n",
       " 'https://github.com/AngelaVC/ask_data_science',\n",
       " 'https://github.com/Lemmibl/Engine',\n",
       " 'https://github.com/naokishibuya/micro-mouse',\n",
       " 'https://github.com/MKLab-ITI/news-popularity-prediction',\n",
       " 'https://github.com/ZhouM1118/NLPForDiscourseStructures',\n",
       " 'https://github.com/renderedtext/render_async',\n",
       " 'https://github.com/lakka/redlock-nodejs',\n",
       " 'https://github.com/rustamserg/swagger-codegen',\n",
       " 'https://github.com/sohaip-hackerDZ/local-root-exploit-',\n",
       " 'https://github.com/FUT/iam',\n",
       " 'https://github.com/saeed3e/webcomponents-poc',\n",
       " 'https://github.com/NCBI-Hackathons/Cancer_Epitopes_CSHL',\n",
       " 'https://github.com/LigerLearn/emacs-course',\n",
       " 'https://github.com/pinard/poporg',\n",
       " 'https://github.com/paulhobbel/kat-api',\n",
       " 'https://github.com/proycon/tscan',\n",
       " 'https://github.com/oauthinaction/oauth-in-action-code',\n",
       " 'https://github.com/Microsoft/OMS-Agent-for-Linux',\n",
       " 'https://github.com/drorgl/ffmpeg.module',\n",
       " 'https://github.com/ProGM/acts-as-taggable-on',\n",
       " 'https://github.com/maxkramer/Timber',\n",
       " 'https://github.com/douban/twemproxy',\n",
       " 'https://github.com/dwqs/vue-resume',\n",
       " 'https://github.com/motiejus/erlualib',\n",
       " 'https://github.com/dbralir/print',\n",
       " 'https://github.com/Himanshi-Khandelwal/open-event-orga-server',\n",
       " 'https://github.com/chenzi/laravel-mns-driver',\n",
       " 'https://github.com/Zarthax/x3dom',\n",
       " 'https://github.com/EHLOVader/anything-order',\n",
       " 'https://github.com/bcr3ative/aoa-contiki',\n",
       " 'https://github.com/MS3FGX/bash-scripts',\n",
       " 'https://github.com/turnercode/opensource-portal',\n",
       " 'https://github.com/mbork/ox-oddmuse',\n",
       " 'https://github.com/timshannon/freehold-sync',\n",
       " 'https://github.com/allaudin/android-architecture',\n",
       " 'https://github.com/popescunsergiu/protractorStarterApp',\n",
       " 'https://github.com/Kennox/rscc',\n",
       " 'https://github.com/ramyrams/InformationSecurity',\n",
       " 'https://github.com/magenta-aps/libreoffice-online-share',\n",
       " 'https://github.com/bitcrab/btsbots',\n",
       " 'https://github.com/kidaa/lit',\n",
       " 'https://github.com/mohsen198x/angular-blog',\n",
       " 'https://github.com/henri/SSIDTHP',\n",
       " 'https://github.com/eed3si9n/scalajson',\n",
       " 'https://github.com/adelinelim/dbdiff',\n",
       " 'https://github.com/evandrojr/evercookie',\n",
       " 'https://github.com/Azure/umock-c',\n",
       " 'https://github.com/nrpatel/cython-hidapi',\n",
       " 'https://github.com/blosm-org/blosm-core',\n",
       " 'https://github.com/tombenner/concurrently',\n",
       " 'https://github.com/codicepulito/data-driven-components',\n",
       " 'https://github.com/trae/d-scripts',\n",
       " 'https://github.com/diogo-fernan/ir-rescue',\n",
       " 'https://github.com/iteratehackerspace/ecmascript-sandbox',\n",
       " 'https://github.com/id03/binoculars',\n",
       " 'https://github.com/stenote/Kohana_Docs_zh_CN',\n",
       " 'https://github.com/letianzj/Strata',\n",
       " 'https://github.com/pzi/middleman-basis',\n",
       " 'https://github.com/dwight/bson-cxx',\n",
       " 'https://github.com/JdeRobot/TeachingRobotics',\n",
       " 'https://github.com/delvingdeep/traffic_sign_classifier',\n",
       " 'https://github.com/ContinuumIO/airflow',\n",
       " 'https://github.com/deravo/jQuery-File-Upload',\n",
       " 'https://github.com/topcoderinc/drone-series',\n",
       " 'https://github.com/Billbastos/en-visualwords',\n",
       " 'https://github.com/AlexBeauchemin/meteor-accounts-twitch',\n",
       " 'https://github.com/WorldOfMora/Issues',\n",
       " 'https://github.com/jonathanstowe/RPi-Device-SMBus',\n",
       " 'https://github.com/protectwise/apone',\n",
       " 'https://github.com/maksimdegtyarev/react-native-alphabetlistview',\n",
       " 'https://github.com/CompleteUnityDeveloper/07-Glitch-Garden',\n",
       " 'https://github.com/AndrewRedican/react-json-editor',\n",
       " 'https://github.com/zbweng/Distributed-LSH',\n",
       " 'https://github.com/cjwsstrm/tweeter',\n",
       " 'https://github.com/timbowhite/elephant-grass-gmail',\n",
       " 'https://github.com/nikolaswise/web-design-workshop',\n",
       " 'https://github.com/cooperhewitt/go-ucd',\n",
       " 'https://github.com/roymacdonald/ofxAfterEffectsTransforms',\n",
       " 'https://github.com/learn-co-students/javascript-reduce-cb-000',\n",
       " 'https://github.com/dren-dk/letsencrypt-nginx-automagic',\n",
       " 'https://github.com/limxing/PhotoView',\n",
       " 'https://github.com/conda-forge/partd-feedstock',\n",
       " 'https://github.com/sardine323/sicp',\n",
       " 'https://github.com/flyve-mdm/flyve-mdm-glpi',\n",
       " 'https://github.com/JilMuriel/Etool_development',\n",
       " 'https://github.com/vitasdk/samples',\n",
       " 'https://github.com/bretonr/Icarus',\n",
       " 'https://github.com/VonRosenchild/models',\n",
       " 'https://github.com/numenta/nupic.core',\n",
       " 'https://github.com/UnionOfRAD/site',\n",
       " 'https://github.com/nishankbhati/Machine-Learning-Tutorials',\n",
       " 'https://github.com/bensampaio/moodle-block_gchat',\n",
       " 'https://github.com/cybercatalyst/qtwebserver-examples',\n",
       " 'https://github.com/Gioyik/getExploit',\n",
       " 'https://github.com/ezimuel/ZendService_Api',\n",
       " 'https://github.com/oddcoder/awesome-awesomeness',\n",
       " 'https://github.com/RyanBalfanz/PyPDS',\n",
       " 'https://github.com/danpaquin/GDAX-Python',\n",
       " 'https://github.com/aanand/deadweight',\n",
       " 'https://github.com/angelov/donut',\n",
       " 'https://github.com/egaoneko/ward',\n",
       " 'https://github.com/nemtsov/koa-json-mask',\n",
       " 'https://github.com/alidcastano/vue-mobiledoc-editor',\n",
       " 'https://github.com/jmfirth/generator-elm-spa',\n",
       " 'https://github.com/emgram769/bar',\n",
       " 'https://github.com/skshetry/Poor-Fox',\n",
       " 'https://github.com/rhmjs/satellite5-docker',\n",
       " 'https://github.com/fanyike/DeepLearning_tutorials',\n",
       " 'https://github.com/Zewo/TurnstileMiddleware',\n",
       " 'https://github.com/foukation/react-native-guide',\n",
       " 'https://github.com/konifar/sketch-export-sample',\n",
       " 'https://github.com/kojety/spring-boot',\n",
       " 'https://github.com/b-studios/Metascala',\n",
       " 'https://github.com/Level/leveldown-hyper',\n",
       " 'https://github.com/jumpinjackie/mapguide-rest',\n",
       " 'https://github.com/kugaevsky/jquery-phoenix',\n",
       " 'https://github.com/eatyrghost/grunt-clientlibs',\n",
       " 'https://github.com/herisanu/etcd-formula',\n",
       " 'https://github.com/Temoto-kun/Projects-Solutions',\n",
       " 'https://github.com/TwilioDevEd/airtng-servlets',\n",
       " 'https://github.com/expo/stripe-expo',\n",
       " 'https://github.com/mickaelandrieu/choisirunelicence',\n",
       " 'https://github.com/lanttern/Kaggler',\n",
       " 'https://github.com/smontoya/authy-python3',\n",
       " 'https://github.com/petegore/DoctrineBehaviors',\n",
       " 'https://github.com/BlackrockDigital/startbootstrap-one-page-wonder',\n",
       " 'https://github.com/syukronrm/reservasiajk',\n",
       " 'https://github.com/Nitro/sidecar',\n",
       " 'https://github.com/mtabb13/firstdata',\n",
       " 'https://github.com/YounGoat/ecmascript.overload2',\n",
       " 'https://github.com/revisualize/google-interview-university',\n",
       " 'https://github.com/OpenTSDB/opentsdb-datasketches',\n",
       " 'https://github.com/clibs/linenoise',\n",
       " 'https://github.com/polm/philtre',\n",
       " 'https://github.com/hypergori/PunBasicsTutorial',\n",
       " 'https://github.com/ialexsilva/2048',\n",
       " 'https://github.com/tmd-gpat/CASTIN',\n",
       " 'https://github.com/camptocamp/tilecloud-chain',\n",
       " 'https://github.com/zzsza/Deep_Learning_starting_with_the_latest_papers',\n",
       " 'https://github.com/JuliaPackageMirrors/DSGE.jl',\n",
       " 'https://github.com/vshn/puppet-in-docker',\n",
       " 'https://github.com/Nosthertus/diet-static-stream',\n",
       " 'https://github.com/Ayush-Kaushik/Medicine_Tracker',\n",
       " 'https://github.com/mgalland/neurofjacobs',\n",
       " 'https://github.com/DarthFubuMVC/fubumvc',\n",
       " 'https://github.com/juju4/ansible-sumocollector',\n",
       " 'https://github.com/JamesLongman/ava-discordbot',\n",
       " 'https://github.com/Acidburn0zzz/openFrameworks',\n",
       " 'https://github.com/uluhonolulu/QCCodingServices.NET',\n",
       " 'https://github.com/mrsmkl/eth-isabelle',\n",
       " 'https://github.com/IngateFuture/apipie-rails',\n",
       " 'https://github.com/TakeshiTseng/ryuInstallHelper',\n",
       " 'https://github.com/thecosmicslug/NESalizer',\n",
       " 'https://github.com/matryer/bitbar',\n",
       " 'https://github.com/DevinYin17/Front-end-Interview-questions',\n",
       " 'https://github.com/ltackmann/dice',\n",
       " 'https://github.com/ezintz/dotfiles',\n",
       " 'https://github.com/jordanorelli/dws',\n",
       " 'https://github.com/colemancda/LicenseGenerator-iOS',\n",
       " 'https://github.com/thinkclay/rails_admin_place_field',\n",
       " 'https://github.com/MaxCDN/bootstrap-cdn',\n",
       " 'https://github.com/ccnokes/SimpleStateMachine',\n",
       " 'https://github.com/laiwei/the-gist',\n",
       " 'https://github.com/alexaubry/ServerCrypto',\n",
       " 'https://github.com/blackducksoftware/sdk-client-tools-protex',\n",
       " 'https://github.com/chaosxly/free-programming-books-zh_CN',\n",
       " 'https://github.com/zalando-incubator/leanix-admin',\n",
       " 'https://github.com/emacs-helm/helm-dictionary',\n",
       " 'https://github.com/MakeBetterMe/iOS_Vendor',\n",
       " 'https://github.com/dimitri/pginstall',\n",
       " 'https://github.com/mailightkun/Clarity-Manga-Reader',\n",
       " 'https://github.com/SEL4PROJ/camkes-arm-vm',\n",
       " 'https://github.com/platformsh/platformsh-example-ezplatform',\n",
       " 'https://github.com/preciousforever/design-studio-kit',\n",
       " 'https://github.com/textlint/textlint-filter-rule-comments',\n",
       " 'https://github.com/ulope/pytest-sftpserver',\n",
       " 'https://github.com/MichaelDrogalis/zombie',\n",
       " 'https://github.com/garasiya/ec2-flask-app',\n",
       " 'https://github.com/jwelker110/neighborhood-map',\n",
       " 'https://github.com/jdavidbakr/signed-s3-filesystem',\n",
       " 'https://github.com/ORNL-TRANSFORM/TRANSFORM-Library',\n",
       " 'https://github.com/joeybaker/dotfiles',\n",
       " 'https://github.com/Cocowyr/Tesseract-OCR-iOS',\n",
       " 'https://github.com/cpoppema/pass-browser-chrome',\n",
       " 'https://github.com/ethanjperez/film',\n",
       " 'https://github.com/invokemedia/wordpress-starter',\n",
       " 'https://github.com/idbmb/GimpLikePhotoshop',\n",
       " 'https://github.com/maccasoft/propeller-vt100-terminal',\n",
       " 'https://github.com/slimsag/gup',\n",
       " 'https://github.com/learn-co-students/method-arguments-lab-web-062617',\n",
       " 'https://github.com/Apicurio/oai-ts-core',\n",
       " 'https://github.com/francodimasi/sdash-front',\n",
       " 'https://github.com/shankajarajapakse/QPGSystem',\n",
       " 'https://github.com/Flaque/thaum',\n",
       " 'https://github.com/WojciechMula/base64simd',\n",
       " 'https://github.com/projectEndings/Endings',\n",
       " 'https://github.com/nightscape/docker-sbt',\n",
       " 'https://github.com/JasonChow1989/welcome-android-master',\n",
       " 'https://github.com/ApolloZhu/FBLA-2017-NLC',\n",
       " 'https://github.com/SoftwareAG/webmethods-integrationserver-wxgenerate',\n",
       " 'https://github.com/mooreniemi/figtree',\n",
       " 'https://github.com/AITGmbH/AIT.DependencyManager',\n",
       " 'https://github.com/Modhi91/DataStructureAndAlgorithms',\n",
       " 'https://github.com/AmineVisionic/CycleGAN',\n",
       " 'https://github.com/tomi0001/praca',\n",
       " 'https://github.com/lsst-sqre/sandbox-jenkins-demo',\n",
       " 'https://github.com/gaoj123/FinalProject',\n",
       " 'https://github.com/bmarkslash7/QPot',\n",
       " 'https://github.com/salahatwa/GoEuro',\n",
       " 'https://github.com/conda-forge/ninja-feedstock',\n",
       " 'https://github.com/aspiwack/finset',\n",
       " 'https://github.com/ognz/Seth',\n",
       " 'https://github.com/dlizarra/spring-boot-react-webpack-starter',\n",
       " 'https://github.com/Steffion/BlockHunt']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model_predictions = model.predict_classes(second_truncated)\n",
    "first_predictions_list = list(first_model_predictions.T[0])\n",
    "\n",
    "first_positive = [{**datum, **{'pred_edu': pred}} for datum, pred in zip(second_raw_training, first_predictions_list) if pred == 1]\n",
    "first_pos_repos = ['https://github.com/' + doc['repo'] for doc in first_positive]\n",
    "first_pos_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
